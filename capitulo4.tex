\chapter{Análise de Resultados} \label{Análise de Resultados}

A base para análise dos resultados foi obtida por meio de uma \textit{survey} aplicada com participantes dos grupos de discussão sobre os sistemas ERPs.\newline
\indent O questionário desta \textit{survey} foi adaptado para a execução da pesquisa foi criado a partir da tradução do questionário aplicado na Alemanha, tendo em vista a pluralidade cultural das regiões brasileiras, foi adicionada a questão referente a região onde o pesquisado reside e trabalha.\newline
\indent Outro fator importante é o \textit{turnover} do colaborador brasileiro que é o maior do mundo, segundo Bispo (2013), esse fato fez com que o fator de exclusão que é o tempo de experiência do colaborador na empresa, fosse reduzido de 2 anos para um ano.\newline
\indent No apêndice A, é possível verificar a cópia do questionário que será divulgado, esse questionário se divide em 6 partes que foram descritas no capítulo execução da pesquisa, subtópico elaboração e estruturação do questionário.\newline
\indent Os resultados compreenderam a avaliação dos sistemas ERP usados, a incerteza dos usuários no uso do sistema, o suporte em situações problemáticas e, finalmente, a avaliação de possíveis soluções para superar as deficiências.\newline
\indent Os resultados incluíram todos os participantes, que tiveram a pergunta específica em seu questionário e não pularam, nem responderam “Não sei”, isso porque a pesquisa original foi realizada dessa forma, logo para que se evite um viés serão utilizados os mesmos parâmetros da pesquisa original. 

\section{Métodos de Análise Utilizados} \label{Métodos de Análise Utilizados}

Conforme Ghosh (1999), para se analisar uma variável de resposta contínua deve-se usar a análise multivariada, que permite estudar e evidenciar as ligações, as semelhanças e diferenças existentes entre todas as variáveis envolvidas no processo.  A necessidade de entender a relação entre diversas variáveis aleatórias faz da análise multivariada uma metodologia com grande potencial de uso.\newline
\indent Desta forma, Ghosh (1999), ainda reitera que o modelo ANOVA tem como objetivo principal verificar se existe uma diferença significativa entre as médias e se os fatores analisados exercem influência na variável de interesse (variável resposta).\newline
\indent Se por um lado, as técnicas estatísticas multivariadas são mais complexas do que aquelas da estatística univariada, por outro lado, apesar de uma razoável complexidade teórica fundamentada na matemática, as técnicas multivariadas, permitem o tratamento de diversas variáveis ao mesmo tempo, podem oferecer ao pesquisador um material bastante robusto para a análise dos dados da pesquisa.

\subsection{Análise Discriminante} \label{Analise Discriminante}

A Análise Discriminante, também denominada Análise do Fator Discriminante ou Análise Discriminante Canônica, foi originalmente desenvolvida na Botânica, e sua aplicação teve como objetivo fazer a distinção de grupos de plantas com base no tamanho e no tipo de folhas, para que, posteriormente, fosse possível classificar as novas espécies encontradas (PREARO et al., 2010).\newline
\indent Entretanto, a aplicação da Análise Discriminante logo se generalizou a outras áreas do conhecimento, inclusive a área de Marketing, sempre em situações em que é possível encontrar grupos de indivíduos e conhecer quais as características que os distinguem uns dos outros.\newline
\indent A seguir, Prearo (2010) indica as premissas presentes na Análise Discriminante:\newline
\indent - Tamanho da amostra (número de casos, indivíduos, observações, entrevistas), deve ser
adequado para permitir a generalização dos resultados, os quais podem ser verificados quanto
à significância estatística dos testes.\newline
\indent - Homoscedasticidade, ocorre quando a variância dos termos de erro parece constante ao longo do domínio da variável preditora, caso os erros não sejam aleatórios há heteroscedasticidade.\newline
\indent - Normalidade multivariada, tem a forma de sinos tridimensionais simétricos quando o eixo de x apresentar os valores de uma determinada variável; o eixo y apresentar a contagem para cada valor da variável de x; e o eixo de z apresentar os valores de qualquer outra variável em consideração.\newline
\indent - Multicolinearidade: refere-se à existência de mais de uma relação linear exata, ao passo que o termo colinearidade refere-se à existência de uma única relação linear.

\subsection{Teste F}

Os testes-F recebem seu nome da sua estatística de teste, F, que recebeu seu nome em homenagem a Sir Ronald Fisher.\newline
\indent O teste F é obtido através de uma razão entre duas variâncias e é  utilizado como um fator para comparar médias de populações normais independentes, sendo que, apresenta desvios no que tange ao tamanho do teste, quando os grupos possuem variâncias populacionais diferentes.\newline
\indent A variância por sua vez é o quadrado do desvio padrão. As variâncias são uma medida de dispersão, sendo que os valores maiores representam uma maior dispersão.\newline
\indent Este teste é mais utilizado quando se comparam modelos estatísticos que foram ajustados a um conjunto de dados, a fim de identificar o modelo que melhor se ajusta à população da qual os dados foram amostrados.

\subsection{Teste t$-$student}

A estatística t foi introduzida em 1908 por William Sealy Gosset, químico da cervejaria Guinness em Dublin, Irlanda (\textit{student} era seu pseudônimo). Gosset havia sido contratado devido à política inovadora de Claude Guinness de recrutar os melhores graduados de Oxford e Cambridge para os cargos de bioquímico e estatístico da indústria Guinness. Gosset desenvolveu o Teste t como um modo barato de monitorar a qualidade da cerveja tipo \textit{stout}. Ele publicou o Teste t na revista acadêmica \textit{Biometrika} em 1908, mas foi forçado a usar seu pseudônimo pelo seu empregador, que acreditava que o fato de usar estatística era um segredo industrial. De fato, a identidade de Gosset não foi reconhecido por seus colegas estatísticos.\newline
\indent O teste t$-$Student ou somente teste t é um teste de hipótese que usa conceitos estatísticos para rejeitar ou não uma hipótese nula quando a estatística de teste (t) segue uma distribuição t$-$student.\newline
\indent Essa premissa é normalmente usada quando a estatística de teste, na verdade, segue uma distribuição normal, mas a variância da população $\sigma$\textsuperscript{2} é desconhecida. Nesse caso, é usada a variância amostral S\textsuperscript{2} e, com esse ajuste, a estatística de teste passa a seguir uma
distribuição t$-$student.\newline
\indent O teste t$-$Student, ou simplesmente teste t é o método mais utilizado para se avaliar as diferenças entre as médias, entre dois grupos. 

\subsection{Teste de Levene}

Levene propôs uma estatística para testar igualdade de variâncias para estudos balanceados, posteriormente foi generalizada para estudos desbalanceados. A estatística é obtida a partir de uma análise de variância com um único fator, já que os níveis são as populações, cada observação i substituída pelo desvio absoluto da variável em relação à média do seu respectivo grupo.\newline
\indent Trata-se de um teste insensível a desvios da normalidade, é um teste robusto, já que, na ausência de normalidade, seu tamanho real é próximo do nível de significância fixado para uma grande variedade de distribuições de probabilidade.

\subsection{Teste de Mann-Whitney}

Os testes não paramétricos são baseados nas posições das observações e não em suas grandezas numéricas. Por isso que se diz que o teste Mann-Whitney compara a mediana ao invés da média, o teste de Mann-Whitney não faz nenhuma suposição quanto a distribuição, populacional.\newline
\indent Testar a mediana ao invés da média pode ser muito vantajoso, pois, a mediana é uma medida de informação mais eficiente que a média, uma vez que não é sensível a valores extremos.

\subsection{Correlação}

Um coeficiente de correlação mede o grau pelo qual duas variáveis tendem a mudar juntas. O coeficiente descreve a força e a direção da relação. \newline
\indent A correlação de pearson avalia a relação linear entre duas variáveis contínuas. Uma relação é linear quando a mudança em uma variável é associada a uma mudança proporcional na outra variável.\newline
\indent O coeficiente de correlação de Pearson pode variar em valor de -1 a +1. Para o coeficiente de correlação de Pearson ser +1, quando uma variável aumenta, as outras variáveis aumentam por uma quantidade consistente.\newline
\indent

